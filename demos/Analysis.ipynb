{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44093a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "An analysis of why wcbtfidf works better in imbalanced classes example.\n",
    "We will have a look at the difference in the vocab considered and why the one used by wcbtfidf is better than tfidf.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe2dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from wcbtfidf import Wcbtfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2180b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv',sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3208f6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.779924\n",
       "0    0.220076\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_target(value):\n",
    "    if value in [2,3,4]:\n",
    "        return 1\n",
    "    \n",
    "    if value in [0,1]:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "df['target'] = df['Sentiment'].apply(change_target)\n",
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9210e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-z0-9]\",\" \",text)\n",
    "    text = re.sub(\"(\\s)+\",\" \",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5b8acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['Phrase'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa9f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 6)\n",
      "(156060, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[['clean_text','target']]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "173d5ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117045,) (117045,)\n",
      "(39015,) (39015,)\n"
     ]
    }
   ],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(df['clean_text'],df['target'],test_size=0.25,random_state=60,stratify=df['target'])\n",
    "\n",
    "print(xtrain.shape,ytrain.shape)\n",
    "print(xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db23b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running base version\n",
      "Precision is 0.7953317083509962\n",
      "Recall is 0.9865260113707318\n",
      "ROC curve is 0.5434027680892792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.10      0.17      8586\n",
      "           1       0.80      0.99      0.88     30429\n",
      "\n",
      "    accuracy                           0.79     39015\n",
      "   macro avg       0.74      0.54      0.53     39015\n",
      "weighted avg       0.77      0.79      0.73     39015\n",
      "\n",
      "Running my version\n",
      "Precision is 0.8031068587400559\n",
      "Recall is 0.9820237273653423\n",
      "ROC curve is 0.5643871257371784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.15      0.24      8586\n",
      "           1       0.80      0.98      0.88     30429\n",
      "\n",
      "    accuracy                           0.80     39015\n",
      "   macro avg       0.75      0.56      0.56     39015\n",
      "weighted avg       0.78      0.80      0.74     39015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_hypothesis(xtrain,xtest,ytrain,ytest,max_feat,model):\n",
    "    \n",
    "    print('Running base version')\n",
    "    tfidf = TfidfVectorizer(max_features=max_feat,stop_words='english')\n",
    "    train_df = pd.DataFrame(tfidf.fit_transform(xtrain).toarray(),columns=tfidf.vocabulary_)\n",
    "    test_df = pd.DataFrame(tfidf.transform(xtest).toarray(),columns=tfidf.vocabulary_)\n",
    "    \n",
    "    \n",
    "    model.fit(train_df,ytrain)\n",
    "    preds = model.predict(test_df)\n",
    "    print(f'Precision is {precision_score(ytest,preds)}')\n",
    "    print(f'Recall is {recall_score(ytest,preds)}')\n",
    "    print(f'ROC curve is {roc_auc_score(ytest,preds)}')\n",
    "    print(classification_report(ytest,preds))\n",
    "    \n",
    "    print('Running my version')\n",
    "    wcbtfidf = Wcbtfidf(max_features=max_feat)\n",
    "    wcbtfidf.fit(xtrain,ytrain)\n",
    "    \n",
    "    train_df = wcbtfidf.transform(xtrain)\n",
    "    test_df = wcbtfidf.transform(xtest)\n",
    "    \n",
    "    model.fit(train_df,ytrain)\n",
    "    preds = model.predict(test_df)\n",
    "    print(f'Precision is {precision_score(ytest,preds)}')\n",
    "    print(f'Recall is {recall_score(ytest,preds)}')\n",
    "    print(f'ROC curve is {roc_auc_score(ytest,preds)}')\n",
    "    print(classification_report(ytest,preds))\n",
    "    return wcbtfidf,tfidf\n",
    "\n",
    "model = LogisticRegression()\n",
    "wcbtfidf_object,tfidf_object = check_hypothesis(xtrain,xtest,ytrain,ytest,300,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f50c9e",
   "metadata": {},
   "source": [
    "## ANALYSIS OF IMPROVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd61e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "0 is the minority class here(Refers to negative reviews of the movies)\n",
    "1 is the majority class here(Refers to positive reviews of the movies)\n",
    "\n",
    "Let us look at the two vocab used by tfidf and wcbtfidf\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21c9a684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    }
   ],
   "source": [
    "# Length Comparison\n",
    "\n",
    "tfidf_vocab = tfidf_object.vocabulary_\n",
    "wcbtfidf_vocab = wcbtfidf_object.combine_vocab\n",
    "\n",
    "print(len(wcbtfidf_vocab),len(tfidf_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01e2cdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act', 'message', 'thought', 'project', 'quirky', 'actor', 'recent', 'romance', 'turn', 'dead', 'stand', 'fresh', 'effort', 'coming', 'boy', 'manages', 'filmmaker', 'stuff', 'teen', 'directed', 'debut', 'feeling', 'energy', 'just', 'easy', 'storytelling', 'horror', 'likely', 'mind', 'does', 'school', 'classic', 'deep', 'filmmaking', 'sure', 'plays', 'role', 'dramatic', 'melodrama', 'laugh', 'ways', 'home', 'personal', 'suspense', 'rich', 'surprisingly', 'wo', 'leave', 'tragedy', 'eyes', 'sort', 'social', 'despite', 'version', 'level', 'especially', 'intelligence', 'offers', 'truly', 'effects', 'did', 'ideas', 'crime', 'audiences', 'death', 'enjoy', 'live', 'john', 'line', 'mr', 'tone', 'charm', 'past', 'shot', 'deeply', 'written', 'believe', 'sex', 'filmmakers', 'turns']\n"
     ]
    }
   ],
   "source": [
    "# Words that are present in tfidf vocab but not in wcbtfidf\n",
    "\n",
    "print(list(set(tfidf_vocab) - set(wcbtfidf_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e6450c",
   "metadata": {},
   "source": [
    "These words can be more categorised as those which are either neutral or lean more towards the positive end like **charm,quirky,classic,enjoy,fresh,laugh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d552d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['show', 'stupid', 'seems', 'fails', 'already', 'bland', 'left', 'still', 'first', 'every', 'us', 'lacks', 'around', 'thin', 'tired', 'could', 'mess', 'another', 'almost', 'worse', 'though', 'ugly', 'yet', 'dumb', 'anyone', 'cheap', 'see', 'sometimes', 'go', 'find', 'part', 'interest', 'cliches', 'nothing', 'always', 'get', 'seem', 'last', 'keep', 'give', 'least', 'also', 'often', 'back', 'take', 'contrived', 'less', 'rather', 'enough', 'whole', 'might', 'whose', 'well', 'ever', 'two', 'without', 'else', 'much', 'three', 'done', 'since', 'made', 'full', 'gags', 're', 'may', 'boring', 'many', 'something', 'none', 'becomes', 'together', 'would', 'anything', 'barely', 'pretentious', 'even', 'slow', 'never', 'one']\n"
     ]
    }
   ],
   "source": [
    "# Words that are present in wcbtfidf but not in tfidf\n",
    "\n",
    "print(list(set(wcbtfidf_vocab) - set(tfidf_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392ca66",
   "metadata": {},
   "source": [
    "Words here can be categorised as either neutral or leaning towards the negative side with words like **worse,lacks,dumb,barely,slow,stupid,boring,pretentious,mess,cheap,ugly,tired,bland.**\n",
    "Words such as these cater more towards the negative class or the minority class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
